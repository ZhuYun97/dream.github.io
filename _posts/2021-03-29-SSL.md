# SSL

## 1. Introduction

this blog will review the existing empirical methods and classify them into three categories: contrastive, generative, contrastive-generative. Analysis how they work and discuss future directions of ssl.

## 2. Definition

self-supervised learning:
the machine predicts any parts of its input for any observed part. This technical term which was first introduced in robotics, the training data is automatically labeled by finding and exploiting the relations between different input sensor signals.

The two classical definitions:

1. Obtain "labels" from the data itself by using a "semi-automatic" process.
2. Predict part of the data from other parts(incompleted, transformed, distorted, or corrupted).

In other words, the model learns to 'recover' whole, or parts of, or merely some features of its original input.

The difference between unsupervised learning and ssl: self-supervised learning is a branch of unsupervised learning since there is no mannual label involved.

Unsupervised learning concentrates on data patterns, such clustering, community discovery, or anomaly detection.

Self-supervised learning aims at recovering, which is still in the paradigm of unsupervised settings.

## 3. Categories

### 3.1 Generative

- Auto-regressive Model:
can be viewed as "Bayes net structure"(directed graph model) $\max \_{\theta} p\_{\theta}(\mathbf{x})=\sum\_{t=1}^{T} \log p\_{\theta}\left(x\_{t} \mid \mathbf{x}\_{1: t-1}\right)$

- Flow-based Model:
The goal of flow-based models is to estimate complex high- dimensional densities p(x) from data. [Recommend this course to learn about flow-based model](https://www.bilibili.com/video/av69736833?p=86)


